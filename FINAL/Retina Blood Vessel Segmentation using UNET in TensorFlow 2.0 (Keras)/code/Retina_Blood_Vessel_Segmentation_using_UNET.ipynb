{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading\n"
      ],
      "metadata": {
        "id": "11Wpca7WcjiA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg9Eabzwchij",
        "outputId": "a7e08180-62b7-46d2-d788-6ebebe513e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from albumentations import HorizontalFlip, VerticalFlip, ElasticTransform, GridDistortion, OpticalDistortion, CoarseDropout\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\" X = Images and Y = masks \"\"\"\n",
        "\n",
        "    train_x = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))\n",
        "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))\n",
        "\n",
        "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))\n",
        "    test_y = sorted(glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "def augment_data(images, masks, save_path, augment=True):\n",
        "    H = 512\n",
        "    W = 512\n",
        "\n",
        "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
        "        \"\"\" Extracting names \"\"\"\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \"\"\" Reading image and mask \"\"\"\n",
        "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        y = imageio.mimread(y)[0]\n",
        "\n",
        "        if augment == True:\n",
        "            aug = HorizontalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x1 = augmented[\"image\"]\n",
        "            y1 = augmented[\"mask\"]\n",
        "\n",
        "            aug = VerticalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x2 = augmented[\"image\"]\n",
        "            y2 = augmented[\"mask\"]\n",
        "\n",
        "            aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x3 = augmented['image']\n",
        "            y3 = augmented['mask']\n",
        "\n",
        "            aug = GridDistortion(p=1)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x4 = augmented['image']\n",
        "            y4 = augmented['mask']\n",
        "\n",
        "            aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x5 = augmented['image']\n",
        "            y5 = augmented['mask']\n",
        "\n",
        "            X = [x, x1, x2, x3, x4, x5]\n",
        "            Y = [y, y1, y2, y3, y4, y5]\n",
        "\n",
        "        else:\n",
        "            X = [x]\n",
        "            Y = [y]\n",
        "\n",
        "        index = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H))\n",
        "            m = cv2.resize(m, (W, H))\n",
        "\n",
        "            if len(X) == 1:\n",
        "                tmp_image_name = f\"{name}.jpg\"\n",
        "                tmp_mask_name = f\"{name}.jpg\"\n",
        "            else:\n",
        "                tmp_image_name = f\"{name}_{index}.jpg\"\n",
        "                tmp_mask_name = f\"{name}_{index}.jpg\"\n",
        "\n",
        "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
        "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
        "\n",
        "            cv2.imwrite(image_path, i)\n",
        "            cv2.imwrite(mask_path, m)\n",
        "\n",
        "            index += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    \"\"\" Load the data \"\"\"\n",
        "    data_path = \"/content/drive/MyDrive/CVPR PROJECT/Project Dataset\"\n",
        "    (train_x, train_y), (test_x, test_y) = load_data(data_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Test: {len(test_x)} - {len(test_y)}\")\n",
        "\n",
        "    \"\"\" Creating directories \"\"\"\n",
        "    create_dir(\"new_data/train/image\")\n",
        "    create_dir(\"new_data/train/mask\")\n",
        "    create_dir(\"new_data/test/image\")\n",
        "    create_dir(\"new_data/test/mask\")\n",
        "\n",
        "    augment_data(train_x, train_y, \"new_data/train/\", augment=False)\n",
        "    augment_data(test_x, test_y, \"new_data/test/\", augment=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZwUzkdbcs_6",
        "outputId": "25938953-961b-43ef-8783-7df88e767c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 20 - 20\n",
            "Test: 20 - 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 38.62it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 38.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model creation"
      ],
      "metadata": {
        "id": "rBh9BPHDcyLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (512, 512, 3)\n",
        "    model = build_unet(input_shape)\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf3QI4x7cy1Z",
        "outputId": "e45700e7-3b04-48bb-9e31-ec139bf9136b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_19 (InputLayer)          [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_342 (Conv2D)            (None, 512, 512, 64  1792        ['input_19[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_324 (Batch  (None, 512, 512, 64  256        ['conv2d_342[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_324 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_324[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_343 (Conv2D)            (None, 512, 512, 64  36928       ['activation_324[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_325 (Batch  (None, 512, 512, 64  256        ['conv2d_343[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_325 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_325[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_72 (MaxPooling2D  (None, 256, 256, 64  0          ['activation_325[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_344 (Conv2D)            (None, 256, 256, 12  73856       ['max_pooling2d_72[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_326 (Batch  (None, 256, 256, 12  512        ['conv2d_344[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_326 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_326[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_345 (Conv2D)            (None, 256, 256, 12  147584      ['activation_326[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_327 (Batch  (None, 256, 256, 12  512        ['conv2d_345[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_327 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_327[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_73 (MaxPooling2D  (None, 128, 128, 12  0          ['activation_327[0][0]']         \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_346 (Conv2D)            (None, 128, 128, 25  295168      ['max_pooling2d_73[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_328 (Batch  (None, 128, 128, 25  1024       ['conv2d_346[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_328 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_328[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_347 (Conv2D)            (None, 128, 128, 25  590080      ['activation_328[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_329 (Batch  (None, 128, 128, 25  1024       ['conv2d_347[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_329 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_329[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_74 (MaxPooling2D  (None, 64, 64, 256)  0          ['activation_329[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_348 (Conv2D)            (None, 64, 64, 512)  1180160     ['max_pooling2d_74[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_330 (Batch  (None, 64, 64, 512)  2048       ['conv2d_348[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_330 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_330[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_349 (Conv2D)            (None, 64, 64, 512)  2359808     ['activation_330[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_331 (Batch  (None, 64, 64, 512)  2048       ['conv2d_349[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_331 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_331[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_75 (MaxPooling2D  (None, 32, 32, 512)  0          ['activation_331[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_350 (Conv2D)            (None, 32, 32, 1024  4719616     ['max_pooling2d_75[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_332 (Batch  (None, 32, 32, 1024  4096       ['conv2d_350[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_332 (Activation)    (None, 32, 32, 1024  0           ['batch_normalization_332[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_351 (Conv2D)            (None, 32, 32, 1024  9438208     ['activation_332[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_333 (Batch  (None, 32, 32, 1024  4096       ['conv2d_351[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_333 (Activation)    (None, 32, 32, 1024  0           ['batch_normalization_333[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_72 (Conv2DTra  (None, 64, 64, 512)  2097664    ['activation_333[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_72 (Concatenate)   (None, 64, 64, 1024  0           ['conv2d_transpose_72[0][0]',    \n",
            "                                )                                 'activation_331[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_352 (Conv2D)            (None, 64, 64, 512)  4719104     ['concatenate_72[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_334 (Batch  (None, 64, 64, 512)  2048       ['conv2d_352[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_334 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_334[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_353 (Conv2D)            (None, 64, 64, 512)  2359808     ['activation_334[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_335 (Batch  (None, 64, 64, 512)  2048       ['conv2d_353[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_335 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_335[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_73 (Conv2DTra  (None, 128, 128, 25  524544     ['activation_335[0][0]']         \n",
            " nspose)                        6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_73 (Concatenate)   (None, 128, 128, 51  0           ['conv2d_transpose_73[0][0]',    \n",
            "                                2)                                'activation_329[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_354 (Conv2D)            (None, 128, 128, 25  1179904     ['concatenate_73[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_336 (Batch  (None, 128, 128, 25  1024       ['conv2d_354[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_336 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_336[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_355 (Conv2D)            (None, 128, 128, 25  590080      ['activation_336[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_337 (Batch  (None, 128, 128, 25  1024       ['conv2d_355[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_337 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_337[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_74 (Conv2DTra  (None, 256, 256, 12  131200     ['activation_337[0][0]']         \n",
            " nspose)                        8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_74 (Concatenate)   (None, 256, 256, 25  0           ['conv2d_transpose_74[0][0]',    \n",
            "                                6)                                'activation_327[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_356 (Conv2D)            (None, 256, 256, 12  295040      ['concatenate_74[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_338 (Batch  (None, 256, 256, 12  512        ['conv2d_356[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_338 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_338[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_357 (Conv2D)            (None, 256, 256, 12  147584      ['activation_338[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_339 (Batch  (None, 256, 256, 12  512        ['conv2d_357[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_339 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_339[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_75 (Conv2DTra  (None, 512, 512, 64  32832      ['activation_339[0][0]']         \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_75 (Concatenate)   (None, 512, 512, 12  0           ['conv2d_transpose_75[0][0]',    \n",
            "                                8)                                'activation_325[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_358 (Conv2D)            (None, 512, 512, 64  73792       ['concatenate_75[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_340 (Batch  (None, 512, 512, 64  256        ['conv2d_358[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_340 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_340[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_359 (Conv2D)            (None, 512, 512, 64  36928       ['activation_340[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_341 (Batch  (None, 512, 512, 64  256        ['conv2d_359[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_341 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_341[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_360 (Conv2D)            (None, 512, 512, 1)  65          ['activation_341[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,055,297\n",
            "Trainable params: 31,043,521\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Matrics "
      ],
      "metadata": {
        "id": "VZ67275hc6ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "tpm6PwwYc6n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model"
      ],
      "metadata": {
        "id": "l4o_UZM8dGTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "\n",
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "\n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)              ## (512, 512, 1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch_size=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(4)\n",
        "    return dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Directory to save files \"\"\"\n",
        "    create_dir(\"files\")\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    batch_size = 2\n",
        "    lr = 1e-4\n",
        "    num_epochs = 100\n",
        "    model_path = os.path.join(\"files\", \"model.h5\")\n",
        "    csv_path = os.path.join(\"files\", \"data.csv\")\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    dataset_path = \"new_data\"\n",
        "    train_path = os.path.join(dataset_path, \"train\")\n",
        "    valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "    train_x, train_y = load_data(train_path)\n",
        "    train_x, train_y = shuffling(train_x, train_y)\n",
        "    valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "    train_steps = len(train_x)//batch_size\n",
        "    valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "    if len(train_x) % batch_size != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch_size != 0:\n",
        "        valid_setps += 1\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = build_unet((H, W, 3))\n",
        "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
        "    # model.summary()\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        TensorBoard(),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=valid_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_setps,\n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyJ9BGf5dHCc",
        "outputId": "0ef4eb4f-5874-479e-93be-e0201fb1be1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 20 - 20\n",
            "Valid: 20 - 20\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7823 - dice_coef: 0.2177 - iou: 0.1224 - recall_14: 0.9161 - precision_14: 0.2992\n",
            "Epoch 1: val_loss improved from inf to 0.85044, saving model to files/model.h5\n",
            "10/10 [==============================] - 25s 1s/step - loss: 0.7823 - dice_coef: 0.2177 - iou: 0.1224 - recall_14: 0.9161 - precision_14: 0.2992 - val_loss: 0.8504 - val_dice_coef: 0.1496 - val_iou: 0.0809 - val_recall_14: 0.9019 - val_precision_14: 0.2085 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7293 - dice_coef: 0.2707 - iou: 0.1567 - recall_14: 0.8302 - precision_14: 0.3476\n",
            "Epoch 2: val_loss did not improve from 0.85044\n",
            "10/10 [==============================] - 7s 671ms/step - loss: 0.7293 - dice_coef: 0.2707 - iou: 0.1567 - recall_14: 0.8302 - precision_14: 0.3476 - val_loss: 0.8505 - val_dice_coef: 0.1495 - val_iou: 0.0808 - val_recall_14: 0.8845 - val_precision_14: 0.2088 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6513 - dice_coef: 0.3487 - iou: 0.2115 - recall_14: 0.6057 - precision_14: 0.5400\n",
            "Epoch 3: val_loss did not improve from 0.85044\n",
            "10/10 [==============================] - 7s 682ms/step - loss: 0.6513 - dice_coef: 0.3487 - iou: 0.2115 - recall_14: 0.6057 - precision_14: 0.5400 - val_loss: 0.8513 - val_dice_coef: 0.1487 - val_iou: 0.0803 - val_recall_14: 8.6835e-04 - val_precision_14: 0.0146 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5774 - dice_coef: 0.4226 - iou: 0.2683 - recall_14: 0.5357 - precision_14: 0.6795\n",
            "Epoch 4: val_loss did not improve from 0.85044\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.5774 - dice_coef: 0.4226 - iou: 0.2683 - recall_14: 0.5357 - precision_14: 0.6795 - val_loss: 0.8529 - val_dice_coef: 0.1471 - val_iou: 0.0794 - val_recall_14: 8.9428e-07 - val_precision_14: 3.8314e-04 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5334 - dice_coef: 0.4666 - iou: 0.3047 - recall_14: 0.4838 - precision_14: 0.7500\n",
            "Epoch 5: val_loss did not improve from 0.85044\n",
            "10/10 [==============================] - 8s 789ms/step - loss: 0.5334 - dice_coef: 0.4666 - iou: 0.3047 - recall_14: 0.4838 - precision_14: 0.7500 - val_loss: 0.8556 - val_dice_coef: 0.1444 - val_iou: 0.0778 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5032 - dice_coef: 0.4968 - iou: 0.3309 - recall_14: 0.4666 - precision_14: 0.7890\n",
            "Epoch 6: val_loss did not improve from 0.85044\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "10/10 [==============================] - 8s 791ms/step - loss: 0.5032 - dice_coef: 0.4968 - iou: 0.3309 - recall_14: 0.4666 - precision_14: 0.7890 - val_loss: 0.8589 - val_dice_coef: 0.1411 - val_iou: 0.0759 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4863 - dice_coef: 0.5137 - iou: 0.3461 - recall_14: 0.4650 - precision_14: 0.8095\n",
            "Epoch 7: val_loss did not improve from 0.85044\n",
            "10/10 [==============================] - 7s 701ms/step - loss: 0.4863 - dice_coef: 0.5137 - iou: 0.3461 - recall_14: 0.4650 - precision_14: 0.8095 - val_loss: 0.8621 - val_dice_coef: 0.1379 - val_iou: 0.0740 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4780 - dice_coef: 0.5220 - iou: 0.3536 - recall_14: 0.4643 - precision_14: 0.8251\n",
            "Epoch 8: val_loss did not improve from 0.85044\n",
            "10/10 [==============================] - 8s 797ms/step - loss: 0.4780 - dice_coef: 0.5220 - iou: 0.3536 - recall_14: 0.4643 - precision_14: 0.8251 - val_loss: 0.8657 - val_dice_coef: 0.1343 - val_iou: 0.0720 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4738 - dice_coef: 0.5262 - iou: 0.3574 - recall_14: 0.4677 - precision_14: 0.8271\n",
            "Epoch 9: val_loss did not improve from 0.85044\n",
            "10/10 [==============================] - 8s 784ms/step - loss: 0.4738 - dice_coef: 0.5262 - iou: 0.3574 - recall_14: 0.4677 - precision_14: 0.8271 - val_loss: 0.8694 - val_dice_coef: 0.1306 - val_iou: 0.0699 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4699 - dice_coef: 0.5301 - iou: 0.3611 - recall_14: 0.4700 - precision_14: 0.8304\n",
            "Epoch 10: val_loss did not improve from 0.85044\n",
            "10/10 [==============================] - 8s 780ms/step - loss: 0.4699 - dice_coef: 0.5301 - iou: 0.3611 - recall_14: 0.4700 - precision_14: 0.8304 - val_loss: 0.8731 - val_dice_coef: 0.1269 - val_iou: 0.0678 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4665 - dice_coef: 0.5335 - iou: 0.3642 - recall_14: 0.4694 - precision_14: 0.8359\n",
            "Epoch 11: val_loss did not improve from 0.85044\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "10/10 [==============================] - 8s 779ms/step - loss: 0.4665 - dice_coef: 0.5335 - iou: 0.3642 - recall_14: 0.4694 - precision_14: 0.8359 - val_loss: 0.8767 - val_dice_coef: 0.1233 - val_iou: 0.0657 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "YIgR60mKdQ3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "\n",
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return ori_x, x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.int32)\n",
        "    return ori_x, x\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "\n",
        "def save_results(ori_x, ori_y, y_pred, save_image_path):\n",
        "    line = np.ones((H, 10, 3)) * 255\n",
        "\n",
        "    ori_y = np.expand_dims(ori_y, axis=-1)\n",
        "    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)\n",
        "\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
        "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) * 255\n",
        "\n",
        "    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred], axis=1)\n",
        "    cv2.imwrite(save_image_path, cat_images)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Save the results in this folder \"\"\"\n",
        "    create_dir(\"results\")\n",
        "\n",
        "    \"\"\" Load the model \"\"\"\n",
        "    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
        "        model = tf.keras.models.load_model(\"files/model.h5\")\n",
        "\n",
        "    \"\"\" Load the dataset \"\"\"\n",
        "    dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "    test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "    \"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "    SCORE = []\n",
        "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "        \"\"\" Extracting name \"\"\"\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \"\"\" Read the image and mask \"\"\"\n",
        "        ori_x, x = read_image(x)\n",
        "        ori_y, y = read_mask(y)\n",
        "\n",
        "        \"\"\" Prediction \"\"\"\n",
        "        y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "        y_pred = y_pred > 0.5\n",
        "        y_pred = y_pred.astype(np.int32)\n",
        "        y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "        \"\"\" Saving the images \"\"\"\n",
        "        save_image_path = f\"results/{name}.png\"\n",
        "        save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "        \"\"\" Flatten the array \"\"\"\n",
        "        y = y.flatten()\n",
        "        y_pred = y_pred.flatten()\n",
        "\n",
        "        \"\"\" Calculate the metrics \"\"\"\n",
        "        acc_value = accuracy_score(y, y_pred)\n",
        "        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "    score = [s[1:] for s in SCORE]\n",
        "    score = np.mean(score, axis=0)\n",
        "    print(f\"Accuracy: {score[0]:0.5f}\")\n",
        "    print(f\"F1: {score[1]:0.5f}\")\n",
        "    print(f\"Jaccard: {score[2]:0.5f}\")\n",
        "    print(f\"Recall: {score[3]:0.5f}\")\n",
        "    print(f\"Precision: {score[4]:0.5f}\")\n",
        "\n",
        "    \"\"\" Saving \"\"\"\n",
        "    df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "    df.to_csv(\"files/score.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93QptMIdRcn",
        "outputId": "309aa1ae-3a47-4dff-8c98-f363dc8b7574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 433ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:00<00:16,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:01<00:11,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:01<00:09,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:02<00:07,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:02<00:06,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:02<00:06,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:03<00:05,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:04<00:06,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:04<00:06,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:05<00:05,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:06<00:05,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:06<00:04,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:07<00:04,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:07<00:03,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:08<00:02,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:08<00:01,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:08<00:01,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:09<00:00,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:09<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:10<00:00,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.10656\n",
            "F1: 0.06564\n",
            "Jaccard: 0.03395\n",
            "Recall: 0.93180\n",
            "Precision: 0.03404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}